# CQ-NIR
We introduce to learn neural implicit representations with quantized coordinates, which reduces the uncertainty and ambiguity in the field during optimization.

## [Project page](https://machineperceptionlab.github.io/CQ-NIR-page/)| [Paper](https://arxiv.org/abs/2308.11025)
This is the official repo for the implementation of **CQ-NIR: Coordinate Quantized Neural Implicit Representations for Multi-view 3D Reconstructionn**.accepted at ICCV 2023.


## Citation

Cite as below if you find this repository is helpful to your project:
```
@inproceedings{sijia2023quantized,
  title={Coordinate Quantized Neural Implicit Representations for Multi-view 3D Reconstruction},
  author={Sijia Jiang and Jing Hua and Zhizhong Han},
  booktitle={{IEEE} International Conference on Computer Vision},
  year={2023}
}
```

## Installation

We provide CQ-NIR on two baselines, UNISURF and NeuS.

#### UNISURF
Make sure that you have all dependencies in place.
You can create an anaconda environment called `unisurf` , you can find out the instruction [here](https://github.com/autonomousvision/unisurf/tree/main). 

#### NeuS
Make sure that you have all dependencies in place.
You can create an anaconda environment called `neus` , you can find out the instruction [here](https://github.com/Totoro97/NeuS).



## Dataset

#### UNISURF

Download the sequences of Dataset generated by the authors of UNISURF, you can find out the data [here](https://github.com/autonomousvision/unisurf/tree/main). 

#### NeuS

Download the sequences of Dataset generated by the authors of NeuS, you can find out the data [here](https://github.com/Totoro97/NeuS).




## Training
#### UNISURF
For training a UNISURF model from scratch run

```
cd unisurf_cq
python train.py configs/DTU/scan_0$id.yaml
```

#### NeuS
For training a NeuS model from scratch
- **Training without mask**

```
cd neus_cq
python exp_runner.py --mode train --conf ./confs/womask.conf --case <case_name>
```

- **Training with mask**

```
cd neus_cq
python exp_runner.py --mode train --conf ./confs/wmask.conf --case <case_name>
```

## Extract mesh from a pretrained model

#### UNISURF
If you just want to quickly extract a mesh from a pre-trained model, you can run our demo with 
```
cd unisurf_cq
python extract.py configs/DTU/scan_0$id.yaml 
```
You can find predicted meshes in `unisurf_cq/out/scan_0$id/`.

#### NeuS

Extract surface from trained model

```
cd neus_cq
python exp_runner.py --mode validate_mesh --conf <config_file> --case <case_name> --is_continue # use latest checkpoint
```

The corresponding mesh can be found in `neus_cq/exp/<case_name>/<exp_name>/meshes/<iter_steps>.ply`.


## Acknowledgement

Some code snippets are borrowed from [UNISURF](https://github.com/autonomousvision/unisurf/tree/main) and [NeuS](https://github.com/Totoro97/NeuS). Thanks for these great projects.
