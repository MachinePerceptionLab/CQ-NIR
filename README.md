# CQ-NIR
We introduce to learn neural implicit representations with quantized coordinates, which reduces the uncertainty and ambiguity in the field during optimization.

## [Project page](https://machineperceptionlab.github.io/CQ-NIR-page/)| [Paper](https://arxiv.org/abs/2308.11025)| [Data](https://www.dropbox.com/sh/w0y8bbdmxzik3uk/AAAaZffBiJevxQzRskoOYcyja?dl=0)
This is the official repo for the implementation of **CQ-NIR: Coordinate Quantized Neural Implicit Representations for Multi-view 3D Reconstructionn**.accepted at ICCV 2023.

## Citation

Cite as below if you find this repository is helpful to your project:
```
@inproceedings{sijia2023quantized,
  title={Coordinate Quantized Neural Implicit Representations for Multi-view 3D Reconstruction},
  author={Sijia Jiang and Jing Hua and Zhizhong Han},
  booktitle={{IEEE} International Conference on Computer Vision},
  year={2023}
}
```

## Dataset

#### Replica

Download the sequences of the Replica Dataset generated by the authors of iMAP into `./data/Replica` folder. 

```bash
bash scripts/download_replica.sh # Released by authors of NICE-SLAM
```



#### ScanNet

Please follow the procedure on [ScanNet](http://www.scan-net.org/) website, and extract color & depth frames from the `.sens` file using the [code](https://github.com/ScanNet/ScanNet/blob/master/SensReader/python/reader.py).
